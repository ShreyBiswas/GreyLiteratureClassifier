{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV = True\n",
    "\n",
    "if DEV:\n",
    "    model_name = \"avsolatorio/GIST-small-Embedding-v0\"\n",
    "else:\n",
    "    model_name = \"avsolatorio/GIST-Embedding-v0\"\n",
    "\n",
    "\n",
    "# model_name = 'jinaai/jina-embeddings-v2-small-en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19368 entries, 0 to 19367\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   url           19368 non-null  object\n",
      " 1   text          19368 non-null  object\n",
      " 2   relevance     19368 non-null  object\n",
      " 3   multiclasses  19368 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 605.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "      <th>multiclasses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>1 \\n \\n \\n2 \\n \\n \\nSubtidal Benthic Invertebr...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Marine Invertebrates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>\\n \\n   \\n  Control of freshwater  \\n  invasi...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Rivers and Lakes, Invasive, Fish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>1 \\n \\nGrassland Conservation \\n2 \\n \\nGrassla...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Grassland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>\\n \\n \\nii \\n \\n \\n \\n \\n \\n \\n  \\nPrimate Co...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Mammals]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>CONSERVATION EVIDENCE SERIES SYNOPSES\\nTerrest...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Mammals]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.conservationevidence.com/synopsis/...   \n",
       "1  https://www.conservationevidence.com/synopsis/...   \n",
       "2  https://www.conservationevidence.com/synopsis/...   \n",
       "3  https://www.conservationevidence.com/synopsis/...   \n",
       "4  https://www.conservationevidence.com/synopsis/...   \n",
       "\n",
       "                                                text relevance  \\\n",
       "0  1 \\n \\n \\n2 \\n \\n \\nSubtidal Benthic Invertebr...  relevant   \n",
       "1   \\n \\n   \\n  Control of freshwater  \\n  invasi...  relevant   \n",
       "2  1 \\n \\nGrassland Conservation \\n2 \\n \\nGrassla...  relevant   \n",
       "3   \\n \\n \\nii \\n \\n \\n \\n \\n \\n \\n  \\nPrimate Co...  relevant   \n",
       "4  CONSERVATION EVIDENCE SERIES SYNOPSES\\nTerrest...  relevant   \n",
       "\n",
       "                         multiclasses  \n",
       "0              [Marine Invertebrates]  \n",
       "1  [Rivers and Lakes, Invasive, Fish]  \n",
       "2                         [Grassland]  \n",
       "3                           [Mammals]  \n",
       "4                           [Mammals]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_labelled_data(path=\"data/level-0.5/data.json\"):\n",
    "    data = pd.read_json(path, encoding=\"latin-1\")\n",
    "    return data\n",
    "\n",
    "\n",
    "data = import_labelled_data(path=\"../../../data/level-0.5/data.json\", )\n",
    "\n",
    "\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0.49, 0.21, 0.3 split\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.3, random_state=42)\n",
    "\n",
    "display(data.info())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b7ff38244c45a0900b20e0d6f44e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728ca276bca0434384e72cb9998a4ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5811 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b253dbb2fe7b4e0fb05a04c3265e9997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4068 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chunking import chunk_dataset_and_explode\n",
    "\n",
    "\n",
    "# roughly 4 characters per token\n",
    "max_len = 512\n",
    "\n",
    "train_data = chunk_dataset_and_explode(train_data, max_len=max_len, overlap=int(max_len * 0.2))\n",
    "test_data = chunk_dataset_and_explode(test_data, max_len=max_len, overlap=int(max_len * 0.2))\n",
    "val_data = chunk_dataset_and_explode(val_data, max_len=max_len, overlap=int(max_len * 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(dataset,label_column: str = 'relevance',num_samples_per_label: int = 100):\n",
    "    return (\n",
    "        dataset\n",
    "        .sample(frac=1,random_state=42)\n",
    "        .groupby(label_column)[dataset.columns]\n",
    "        .apply(lambda x: x.sample(min(num_samples_per_label,len(x)),random_state=42),include_groups=True).reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "if DEV:\n",
    "    train_data = stratified_sample(train_data,num_samples_per_label=1000)\n",
    "    val_data = val_data.sample(100,random_state=42)\n",
    "    test_data = test_data.sample(200,random_state=42)\n",
    "else:\n",
    "    train_data = train_data.sample(frac=1,random_state=42)\n",
    "    val_data = val_data.sample(500,random_state=42)\n",
    "    test_data = test_data.sample(frac=1,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "      <th>multiclasses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17236</td>\n",
       "      <td>http://www.world-psi.org/sites/default/files/d...</td>\n",
       "      <td>struction, n u Marchands m s e c i Source: WIE...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17698</td>\n",
       "      <td>https://deerruncdd.com/wp-content/uploads/2024...</td>\n",
       "      <td>ctly prohibited at the pool, with the exceptio...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9087</td>\n",
       "      <td>https://www.mwe.go.ug/sites/default/files/libr...</td>\n",
       "      <td>ined after infection has occurred. These objec...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13668</td>\n",
       "      <td>https://documents1.worldbank.org/curated/en/57...</td>\n",
       "      <td>on and new sources of FX income. 233. This are...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11745</td>\n",
       "      <td>https://worldjusticeproject.org/sites/default/...</td>\n",
       "      <td>Leona √Åfrica Subsahariana Bajo Serbia Eastern...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>78</td>\n",
       "      <td>https://www.wetlands.org/wp-content/uploads/20...</td>\n",
       "      <td>pecialists in each flamingo range state, those...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Animals Ex-Situ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4747</td>\n",
       "      <td>https://www.conservationevidence.com/individua...</td>\n",
       "      <td>ge, compared to conventional tillage, in two o...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Farmland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>4030</td>\n",
       "      <td>https://www.conservationevidence.com/individua...</td>\n",
       "      <td>ubterranean clover Trifolium subterraneum and ...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Farmland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>13</td>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>ackground \\nIn captivity, amphibian diets are ...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Animals Ex-Situ, Captivity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>21</td>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>species become established. \\n \\nRelated inte...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Shrubland]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chunk_id                                                url  \\\n",
       "0        17236  http://www.world-psi.org/sites/default/files/d...   \n",
       "1        17698  https://deerruncdd.com/wp-content/uploads/2024...   \n",
       "2         9087  https://www.mwe.go.ug/sites/default/files/libr...   \n",
       "3        13668  https://documents1.worldbank.org/curated/en/57...   \n",
       "4        11745  https://worldjusticeproject.org/sites/default/...   \n",
       "...        ...                                                ...   \n",
       "1995        78  https://www.wetlands.org/wp-content/uploads/20...   \n",
       "1996      4747  https://www.conservationevidence.com/individua...   \n",
       "1997      4030  https://www.conservationevidence.com/individua...   \n",
       "1998        13  https://www.conservationevidence.com/synopsis/...   \n",
       "1999        21  https://www.conservationevidence.com/synopsis/...   \n",
       "\n",
       "                                                   text   relevance  \\\n",
       "0     struction, n u Marchands m s e c i Source: WIE...  irrelevant   \n",
       "1     ctly prohibited at the pool, with the exceptio...  irrelevant   \n",
       "2     ined after infection has occurred. These objec...  irrelevant   \n",
       "3     on and new sources of FX income. 233. This are...  irrelevant   \n",
       "4      Leona √Åfrica Subsahariana Bajo Serbia Eastern...  irrelevant   \n",
       "...                                                 ...         ...   \n",
       "1995  pecialists in each flamingo range state, those...    relevant   \n",
       "1996  ge, compared to conventional tillage, in two o...    relevant   \n",
       "1997  ubterranean clover Trifolium subterraneum and ...    relevant   \n",
       "1998  ackground \\nIn captivity, amphibian diets are ...    relevant   \n",
       "1999   species become established. \\n \\nRelated inte...    relevant   \n",
       "\n",
       "                      multiclasses  \n",
       "0                               []  \n",
       "1                               []  \n",
       "2                               []  \n",
       "3                               []  \n",
       "4                               []  \n",
       "...                            ...  \n",
       "1995             [Animals Ex-Situ]  \n",
       "1996                    [Farmland]  \n",
       "1997                    [Farmland]  \n",
       "1998  [Animals Ex-Situ, Captivity]  \n",
       "1999                   [Shrubland]  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chunk_id', 'url', 'text', 'relevance', 'multiclasses'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data, split=\"train\")\n",
    "test_dataset = Dataset.from_pandas(test_data, split=\"test\")\n",
    "val_dataset = Dataset.from_pandas(val_data, split=\"val\")\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! had to modify FastFitTrainer to at /fastfit/train.py, line 879, to add trust_remote_code=True to the loading of 'accuracy' metrics\n",
    "#! don't know why it's not default, since accuracy is the default in fastfit\n",
    "\n",
    "\n",
    "\n",
    "#! IMPORTANT: another change in FastFitTrainer, also at line 879; comment out and replace the fixed version above\n",
    "#! since load_metric is deprecated in favour of evaluate.load()\n",
    "#! added functionality for sending in multiple metrics to evaluate at once\n",
    "#! added macro averages for non-accuracy metrics too\n",
    "#! essentially, copy the below code to replace line 879\n",
    "#! and delete the compute_metrics function already there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert into line 879.\n",
    "\n",
    "```python\n",
    "        # metric = load_metric(self.data_args.metric_name, experiment_id=uuid.uuid4())\n",
    "        from evaluate import combine, load\n",
    "        if type(self.data_args.metric_name) == str: # single metric name\n",
    "            metrics = [load(self.data_args.metric_name, experiment_id=uuid.uuid4())]\n",
    "        elif type(self.data_args.metric_name) == list: # compute multiple metrics\n",
    "            metrics = [load(metric,experiment_id=uuid.uuid4()) for metric in self.data_args.metric_name]\n",
    "\n",
    "        # You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "        # predictions and label_ids field) and has to return a dictionary string to float.\n",
    "        def compute_metrics(p: EvalPrediction):\n",
    "            predictions = (\n",
    "                p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "            )\n",
    "            predictions = (\n",
    "                np.squeeze(predictions)\n",
    "                if self.is_regression\n",
    "                else np.argmax(predictions, axis=1)\n",
    "            )\n",
    "            references = p.label_ids\n",
    "\n",
    "            results = {}\n",
    "\n",
    "            for metric in metrics:\n",
    "                if metric.name != 'accuracy':\n",
    "                    results.update(metric.compute(predictions=predictions, references=references,average='macro'))\n",
    "                else:\n",
    "                    results.update(metric.compute(predictions=predictions, references=references))\n",
    "\n",
    "            return results\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/16/2024 09:52:14 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/GreyLit/venv/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1355e55890498eb65daf7156f3d3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/2000 [00:00<?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa45601e3b9046e6ad8f821879897c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/100 [00:00<?,‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e22f6e7df0467eaaabdcc4a9ecbc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/200 [00:00<?,‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7304cf9ac4435e9e1dc52eedd1e73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9315bb2425848b092ecee9731ffe9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13ae04b45814ee5907ebd7db29a5da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastfit import FastFitTrainer\n",
    "\n",
    "# same args as the huggingface TrainingArguments\n",
    "if DEV:\n",
    "    output_dir = f'models/relevance/dev/{model_name}'\n",
    "else:\n",
    "    output_dir = f'models/relevance/{model_name}'\n",
    "\n",
    "trainer = FastFitTrainer(\n",
    "    model_name_or_path=model_name,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    label_column_name='relevance',\n",
    "    text_column_name=\"text\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    max_text_length=max_len,\n",
    "    num_repeats=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy='epoch',\n",
    "    metric_name=['precision','recall','f1','accuracy'],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='precision',\n",
    "    fp16=True,\n",
    "    fp16_opt_level=\"O2\",\n",
    "    fp16_full_eval=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 3090\n",
      "12.1\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "print(torch.version.cuda)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(trainer.model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:1198] 2024-08-16 09:52:34,372 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 70/315 00:19 < 01:09, 3.52 it/s, Epoch 1.10/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.741300</td>\n",
       "      <td>3.926953</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#! another fastfit library modification\n",
    "#! in /fastfit/train.py, line 971, cast ignore_keys_for_eval from type set to a list\n",
    "#! since it gets concatenated to a list later on, and otherwise crashes\n",
    "#! note that since we've added lines above, this is now line 1003\n",
    "#! the line beginning ignore_keys_for_eval={\"doc_input_ids\",\"doc_attention_mask\",\"labels\"}\n",
    "\n",
    "\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        5.0\n",
      "  eval_accuracy           =       0.97\n",
      "  eval_f1                 =     0.8919\n",
      "  eval_loss               =     1.8722\n",
      "  eval_precision          =     0.8333\n",
      "  eval_recall             =      0.984\n",
      "  eval_runtime            = 0:00:01.52\n",
      "  eval_samples            =        100\n",
      "  eval_samples_per_second =     65.462\n",
      "  eval_steps_per_second   =     16.365\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {results[\"eval_accuracy\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test metrics *****\n",
      "  epoch                   =        5.0\n",
      "  eval_accuracy           =       0.97\n",
      "  eval_f1                 =     0.9167\n",
      "  eval_loss               =     1.8095\n",
      "  eval_precision          =     0.8696\n",
      "  eval_recall             =     0.9836\n",
      "  eval_runtime            = 0:00:02.96\n",
      "  eval_samples_per_second =     67.509\n",
      "  eval_steps_per_second   =     16.877\n",
      "  test_samples            =        200\n"
     ]
    }
   ],
   "source": [
    "results = trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of files processed per second: 36.792405\n"
     ]
    }
   ],
   "source": [
    "print(f'Estimate of files processed per second:', results[\"eval_samples_per_second\"]*len(train_data['chunk_id'].unique())/len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if DEV:\n",
    "#     from os import makedirs, path\n",
    "#     if not path.exists(f'models/relevance/dev/{model_name}'):\n",
    "#         makedirs(f'models/relevance/dev/{model_name}')\n",
    "\n",
    "#     model.save_pretrained(f'models/relevance/dev/{model_name}')\n",
    "\n",
    "# else:\n",
    "#     model.save_pretrained(f'models/relevance/{model_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreyLiteratureClassifier-pwi3iMQR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
