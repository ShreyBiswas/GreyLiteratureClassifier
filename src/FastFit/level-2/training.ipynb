{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating Actions from conservation-adjacent texts\n",
    "'Irrelevant' now represents non-actions, 'Relevant' represents action evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV = True\n",
    "\n",
    "if DEV:\n",
    "    model_name = \"avsolatorio/GIST-small-Embedding-v0\"\n",
    "else:\n",
    "    model_name = \"avsolatorio/GIST-Embedding-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10436 entries, 0 to 10435\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   url           10436 non-null  object \n",
      " 1   text          10436 non-null  object \n",
      " 2   relevance     10436 non-null  object \n",
      " 3   multiclasses  10436 non-null  object \n",
      " 4   score         223 non-null    float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 407.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "      <th>multiclasses</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>1 \\n \\n \\n2 \\n \\n \\nSubtidal Benthic Invertebr...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Marine Invertebrates]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>\\n \\n   \\n  Control of freshwater  \\n  invasi...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Fish, Rivers and Lakes, Invasive]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>1 \\n \\nGrassland Conservation \\n2 \\n \\nGrassla...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Grassland]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>\\n \\n \\nii \\n \\n \\n \\n \\n \\n \\n  \\nPrimate Co...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Mammals]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>CONSERVATION EVIDENCE SERIES SYNOPSES\\nTerrest...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Mammals]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.conservationevidence.com/synopsis/...   \n",
       "1  https://www.conservationevidence.com/synopsis/...   \n",
       "2  https://www.conservationevidence.com/synopsis/...   \n",
       "3  https://www.conservationevidence.com/synopsis/...   \n",
       "4  https://www.conservationevidence.com/synopsis/...   \n",
       "\n",
       "                                                text relevance  \\\n",
       "0  1 \\n \\n \\n2 \\n \\n \\nSubtidal Benthic Invertebr...  relevant   \n",
       "1   \\n \\n   \\n  Control of freshwater  \\n  invasi...  relevant   \n",
       "2  1 \\n \\nGrassland Conservation \\n2 \\n \\nGrassla...  relevant   \n",
       "3   \\n \\n \\nii \\n \\n \\n \\n \\n \\n \\n  \\nPrimate Co...  relevant   \n",
       "4  CONSERVATION EVIDENCE SERIES SYNOPSES\\nTerrest...  relevant   \n",
       "\n",
       "                         multiclasses  score  \n",
       "0              [Marine Invertebrates]    NaN  \n",
       "1  [Fish, Rivers and Lakes, Invasive]    NaN  \n",
       "2                         [Grassland]    NaN  \n",
       "3                           [Mammals]    NaN  \n",
       "4                           [Mammals]    NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_labelled_data(path=\"data/level-1.5/merged/data.json\"):\n",
    "    data = pd.read_json(path, encoding=\"latin-1\")\n",
    "    return data\n",
    "\n",
    "\n",
    "data = import_labelled_data(path=\"../../../data/level-1.5/merged/data.json\", )\n",
    "\n",
    "\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0.49, 0.21, 0.3 split\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.3, random_state=42)\n",
    "\n",
    "display(data.info())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542bdec53a7940eeab38ee7b18283292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592eb151f90849c683efc1866ac64172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c13d77247347338789bc1451f91f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chunking import chunk_dataset_and_explode\n",
    "\n",
    "\n",
    "# roughly 4 characters per token\n",
    "max_len = 512\n",
    "\n",
    "train_data = chunk_dataset_and_explode(train_data, max_len=max_len, overlap=int(max_len * 0.2))\n",
    "test_data = chunk_dataset_and_explode(test_data, max_len=max_len, overlap=int(max_len * 0.2))\n",
    "val_data = chunk_dataset_and_explode(val_data, max_len=max_len, overlap=int(max_len * 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(dataset,label_column: str = 'relevance',num_samples_per_label: int = 100):\n",
    "    return (\n",
    "        dataset\n",
    "        .sample(frac=1,random_state=42)\n",
    "        .groupby(label_column)[dataset.columns]\n",
    "        .apply(lambda x: x.sample(min(num_samples_per_label,len(x)),random_state=42),include_groups=True).reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "if DEV:\n",
    "    train_data = stratified_sample(train_data,num_samples_per_label=500)\n",
    "    val_data = val_data.sample(100,random_state=42)\n",
    "    test_data = test_data.sample(200,random_state=42)\n",
    "else:\n",
    "    train_data = train_data.sample(frac=1,random_state=42)\n",
    "    val_data = val_data.sample(500,random_state=42)\n",
    "    test_data = test_data.sample(frac=1,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "      <th>multiclasses</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10130</td>\n",
       "      <td>https://www.wetlands.org/publications/flamingo...</td>\n",
       "      <td>chilensis \\nSite \\nLat. \\nLong.  \\n2008 \\n200...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[Birds]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10364</td>\n",
       "      <td>https://www.zooreach.org/ZOO_WILD_Activities/2...</td>\n",
       "      <td>guide ‚Äì how best you can use this The SahyƒÅdr...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.984325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10369</td>\n",
       "      <td>https://www.forestfoundation.ph/wp-content/upl...</td>\n",
       "      <td>ish Philippine tropical forests. %e TFCA its g...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.982479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10352</td>\n",
       "      <td>https://digitalarchive.worldfishcenter.org/bit...</td>\n",
       "      <td>10,480 (3.6%) 22 ‚ñ™ area, topography and soils...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.986896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10382</td>\n",
       "      <td>https://www.wyomingwildsheep.org/wp-content/up...</td>\n",
       "      <td>tiful area of Wyoming with hunter when we acce...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.979519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>85 fawns/adult female; before control: 0.84 fa...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Mammals]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>...... \\n83 \\n2.23. Apply herbicide before see...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Grassland]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3957</td>\n",
       "      <td>https://www.conservationevidence.com/individua...</td>\n",
       "      <td>12,000 tadpoles were raised in captivity. Tad...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Amphibians]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>16</td>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>A review of a houbara bustard Chlamydotis undu...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Birds]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>21</td>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>n and removal affect soils and vegetation in t...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Shrubland]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chunk_id                                                url  \\\n",
       "0       10130  https://www.wetlands.org/publications/flamingo...   \n",
       "1       10364  https://www.zooreach.org/ZOO_WILD_Activities/2...   \n",
       "2       10369  https://www.forestfoundation.ph/wp-content/upl...   \n",
       "3       10352  https://digitalarchive.worldfishcenter.org/bit...   \n",
       "4       10382  https://www.wyomingwildsheep.org/wp-content/up...   \n",
       "..        ...                                                ...   \n",
       "995         4  https://www.conservationevidence.com/synopsis/...   \n",
       "996         2  https://www.conservationevidence.com/synopsis/...   \n",
       "997      3957  https://www.conservationevidence.com/individua...   \n",
       "998        16  https://www.conservationevidence.com/synopsis/...   \n",
       "999        21  https://www.conservationevidence.com/synopsis/...   \n",
       "\n",
       "                                                  text   relevance  \\\n",
       "0     chilensis \\nSite \\nLat. \\nLong.  \\n2008 \\n200...  irrelevant   \n",
       "1     guide ‚Äì how best you can use this The SahyƒÅdr...  irrelevant   \n",
       "2    ish Philippine tropical forests. %e TFCA its g...  irrelevant   \n",
       "3     10,480 (3.6%) 22 ‚ñ™ area, topography and soils...  irrelevant   \n",
       "4    tiful area of Wyoming with hunter when we acce...  irrelevant   \n",
       "..                                                 ...         ...   \n",
       "995  85 fawns/adult female; before control: 0.84 fa...    relevant   \n",
       "996  ...... \\n83 \\n2.23. Apply herbicide before see...    relevant   \n",
       "997   12,000 tadpoles were raised in captivity. Tad...    relevant   \n",
       "998  A review of a houbara bustard Chlamydotis undu...    relevant   \n",
       "999  n and removal affect soils and vegetation in t...    relevant   \n",
       "\n",
       "     multiclasses     score  \n",
       "0         [Birds]       NaN  \n",
       "1              []  0.984325  \n",
       "2              []  0.982479  \n",
       "3              []  0.986896  \n",
       "4              []  0.979519  \n",
       "..            ...       ...  \n",
       "995     [Mammals]       NaN  \n",
       "996   [Grassland]       NaN  \n",
       "997  [Amphibians]       NaN  \n",
       "998       [Birds]       NaN  \n",
       "999   [Shrubland]       NaN  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chunk_id', 'url', 'text', 'relevance', 'multiclasses', 'score'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data, split=\"train\")\n",
    "test_dataset = Dataset.from_pandas(test_data, split=\"test\")\n",
    "val_dataset = Dataset.from_pandas(val_data, split=\"val\")\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! had to modify FastFitTrainer to at /fastfit/train.py, line 879, to add trust_remote_code=True to the loading of 'accuracy' metrics\n",
    "#! don't know why it's not default, since accuracy is the default in fastfit\n",
    "\n",
    "\n",
    "\n",
    "#! IMPORTANT: another change in FastFitTrainer, also at line 879; comment out and replace the fixed version above\n",
    "#! since load_metric is deprecated in favour of evaluate.load()\n",
    "#! added functionality for sending in multiple metrics to evaluate at once\n",
    "#! added macro averages for non-accuracy metrics too\n",
    "#! essentially, copy the below code to replace line 879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert into line 879.\n",
    "\n",
    "```python\n",
    "        # metric = load_metric(self.data_args.metric_name, experiment_id=uuid.uuid4())\n",
    "        from evaluate import combine, load\n",
    "        if type(self.data_args.metric_name) == str: # single metric name\n",
    "            metrics = [load(self.data_args.metric_name, experiment_id=uuid.uuid4())]\n",
    "        elif type(self.data_args.metric_name) == list: # compute multiple metrics\n",
    "            metrics = [load(metric,experiment_id=uuid.uuid4()) for metric in self.data_args.metric_name]\n",
    "\n",
    "        # You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "        # predictions and label_ids field) and has to return a dictionary string to float.\n",
    "        def compute_metrics(p: EvalPrediction):\n",
    "            predictions = (\n",
    "                p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "            )\n",
    "            predictions = (\n",
    "                np.squeeze(predictions)\n",
    "                if self.is_regression\n",
    "                else np.argmax(predictions, axis=1)\n",
    "            )\n",
    "            references = p.label_ids\n",
    "\n",
    "            results = {}\n",
    "\n",
    "            for metric in metrics:\n",
    "                if metric.name != 'accuracy':\n",
    "                    results.update(metric.compute(predictions=predictions, references=references,average='macro'))\n",
    "                else:\n",
    "                    results.update(metric.compute(predictions=predictions, references=references))\n",
    "\n",
    "            return results\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/29/2024 11:08:28 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/GreyLiteratureClassifier-eJH_GeT1/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd00bc3caa14b8d935e7f3ac24c5694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/1000 [00:00<?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a405eb907b4aaba695c610101d0d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/100 [00:00<?,‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea78332c54846e2adf064d504ad8f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/200 [00:00<?,‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1947b7537d8464da6e47fc2cbdde0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8ab2fd2bf940d3912be435d72a5ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749d8a2d67a74a4ca9433856f70351e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastfit import FastFitTrainer\n",
    "\n",
    "# same args as the huggingface TrainingArguments\n",
    "if DEV:\n",
    "    output_dir = f'models/relevance/dev/{model_name}'\n",
    "else:\n",
    "    output_dir = f'models/relevance/{model_name}'\n",
    "\n",
    "trainer = FastFitTrainer(\n",
    "    model_name_or_path=model_name,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    label_column_name='relevance',\n",
    "    text_column_name=\"text\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    max_text_length=512,\n",
    "    num_repeats=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy='epoch',\n",
    "    metric_name=['precision','recall','f1','accuracy'],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='precision',\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 3090\n",
      "12.1\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "print(torch.version.cuda)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(trainer.model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:1198] 2024-07-29 11:08:49,046 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 01:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.779000</td>\n",
       "      <td>4.252465</td>\n",
       "      <td>0.949780</td>\n",
       "      <td>0.950321</td>\n",
       "      <td>0.949955</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.328300</td>\n",
       "      <td>4.226601</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.940705</td>\n",
       "      <td>0.939976</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.209900</td>\n",
       "      <td>4.205118</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.166500</td>\n",
       "      <td>4.267502</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.142900</td>\n",
       "      <td>4.305388</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.133600</td>\n",
       "      <td>4.349062</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.129400</td>\n",
       "      <td>4.436815</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.127300</td>\n",
       "      <td>4.390973</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.126200</td>\n",
       "      <td>4.398200</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.129900</td>\n",
       "      <td>4.396714</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     4.2273\n",
      "  train_runtime            = 0:01:23.01\n",
      "  train_samples            =       1000\n",
      "  train_samples_per_second =    120.462\n",
      "  train_steps_per_second   =      1.927\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#! another fastfit library modification\n",
    "#! in /fastfit/train.py, line 971, change ignore_keys_for_eval from type set to a list\n",
    "#! since it gets concatenated to a list later on\n",
    "#! note that since we've added lines above, this is now line 981\n",
    "#! the line beginning ignore_keys_for_eval={\"doc_input_ids\",\"doc_attention_mask\",\"labels\"}\n",
    "\n",
    "\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =       0.96\n",
      "  eval_f1                 =     0.9599\n",
      "  eval_loss               =     4.2051\n",
      "  eval_precision          =     0.9599\n",
      "  eval_recall             =     0.9599\n",
      "  eval_runtime            = 0:00:00.49\n",
      "  eval_samples            =        100\n",
      "  eval_samples_per_second =    201.895\n",
      "  eval_steps_per_second   =      4.038\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.205118179321289,\n",
       " 'eval_precision': 0.9599358974358975,\n",
       " 'eval_recall': 0.9599358974358975,\n",
       " 'eval_f1': 0.9599358974358975,\n",
       " 'eval_accuracy': 0.96,\n",
       " 'eval_runtime': 0.4953,\n",
       " 'eval_samples_per_second': 201.895,\n",
       " 'eval_steps_per_second': 4.038,\n",
       " 'epoch': 10.0,\n",
       " 'eval_samples': 100}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {results[\"eval_accuracy\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =       0.93\n",
      "  eval_f1                 =     0.9196\n",
      "  eval_loss               =     4.4866\n",
      "  eval_precision          =     0.9196\n",
      "  eval_recall             =     0.9196\n",
      "  eval_runtime            = 0:00:00.93\n",
      "  eval_samples_per_second =    213.762\n",
      "  eval_steps_per_second   =      4.275\n",
      "  test_samples            =        200\n"
     ]
    }
   ],
   "source": [
    "results = trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from os import makedirs, path\n",
    "if not path.exists(f'models/relevance/dev/{model_name}'):\n",
    "    makedirs(f'models/relevance/dev/{model_name}')\n",
    "\n",
    "model.save_pretrained(f'models/relevance/dev/{model_name}')\n",
    "\n",
    "if not DEV:\n",
    "    model.save_pretrained(f'models/relevance/{model_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreyLiteratureClassifier-pwi3iMQR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
