{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating Actions from conservation-adjacent texts\n",
    "'Irrelevant' now represents non-actions, 'Relevant' represents action evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV = True\n",
    "\n",
    "if DEV:\n",
    "    model_name = \"avsolatorio/GIST-small-Embedding-v0\"\n",
    "else:\n",
    "    model_name = \"avsolatorio/GIST-Embedding-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8803 entries, 0 to 8802\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   url           8803 non-null   object \n",
      " 1   text          8803 non-null   object \n",
      " 2   relevance     8803 non-null   object \n",
      " 3   multiclasses  8803 non-null   object \n",
      " 4   score-lv1     207 non-null    float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 344.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "      <th>multiclasses</th>\n",
       "      <th>score-lv1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>1 \\n \\n \\n2 \\n \\n \\nSubtidal Benthic Invertebr...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Marine Invertebrates]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>\\n \\n   \\n  Control of freshwater  \\n  invasi...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Fish, Rivers and Lakes, Invasive]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>1 \\n \\nGrassland Conservation \\n2 \\n \\nGrassla...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Grassland]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>\\n \\n \\nii \\n \\n \\n \\n \\n \\n \\n  \\nPrimate Co...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Mammals]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>CONSERVATION EVIDENCE SERIES SYNOPSES\\nTerrest...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Mammals]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.conservationevidence.com/synopsis/...   \n",
       "1  https://www.conservationevidence.com/synopsis/...   \n",
       "2  https://www.conservationevidence.com/synopsis/...   \n",
       "3  https://www.conservationevidence.com/synopsis/...   \n",
       "4  https://www.conservationevidence.com/synopsis/...   \n",
       "\n",
       "                                                text relevance  \\\n",
       "0  1 \\n \\n \\n2 \\n \\n \\nSubtidal Benthic Invertebr...  relevant   \n",
       "1   \\n \\n   \\n  Control of freshwater  \\n  invasi...  relevant   \n",
       "2  1 \\n \\nGrassland Conservation \\n2 \\n \\nGrassla...  relevant   \n",
       "3   \\n \\n \\nii \\n \\n \\n \\n \\n \\n \\n  \\nPrimate Co...  relevant   \n",
       "4  CONSERVATION EVIDENCE SERIES SYNOPSES\\nTerrest...  relevant   \n",
       "\n",
       "                         multiclasses  score-lv1  \n",
       "0              [Marine Invertebrates]        NaN  \n",
       "1  [Fish, Rivers and Lakes, Invasive]        NaN  \n",
       "2                         [Grassland]        NaN  \n",
       "3                           [Mammals]        NaN  \n",
       "4                           [Mammals]        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_labelled_data(path=\"data/level-1.5/merged/data.json\"):\n",
    "    data = pd.read_json(path, encoding=\"latin-1\")\n",
    "    return data\n",
    "\n",
    "\n",
    "data = import_labelled_data(path=\"../../../data/level-1.5/merged/data.json\", )\n",
    "\n",
    "\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0.45 train, 0.15 val, 0.4 test\n",
    "train_data, test_data = train_test_split(data, test_size=0.4, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)\n",
    "\n",
    "display(data.info())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374062ff58a24d40b54c75682b0539dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159b94f37987444685c5ba3d0e80e2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3522 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e144581aae425e9d9644f70ca610e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1321 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chunking import chunk_dataset_and_explode\n",
    "\n",
    "\n",
    "# roughly 4 characters per token\n",
    "max_len = 512\n",
    "\n",
    "train_data = chunk_dataset_and_explode(train_data, max_len=max_len, overlap=int(max_len * 0.2))\n",
    "test_data = chunk_dataset_and_explode(test_data, max_len=max_len, overlap=int(max_len * 0.2))\n",
    "val_data = chunk_dataset_and_explode(val_data, max_len=max_len, overlap=int(max_len * 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "relevant      51706\n",
       "irrelevant    39541\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['relevance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(dataset,label_column: str = 'relevance',num_samples_per_label: int = 100):\n",
    "    return (\n",
    "        dataset\n",
    "        .sample(frac=1,random_state=42)\n",
    "        .groupby(label_column)[dataset.columns]\n",
    "        .apply(lambda x: x.sample(min(num_samples_per_label,len(x)),random_state=42),include_groups=True).reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def sorted_stratified_sample(dataset,label_column: str = 'relevance', sorting_column: str = 'score-lv1', num_samples_per_label: int = 100):\n",
    "    # get top num_samples_per_label samples per label\n",
    "    return (\n",
    "        dataset\n",
    "        .sort_values(sorting_column,ascending=False)\n",
    "        .groupby(label_column)[dataset.columns]\n",
    "        .apply(lambda x: x.head(min(num_samples_per_label,len(x))),include_groups=True).reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "if DEV:\n",
    "    train_data = sorted_stratified_sample(train_data,label_column='relevance', sorting_column='score-lv1', num_samples_per_label=250)\n",
    "    val_data = val_data.sample(100,random_state=42)\n",
    "    test_data = test_data.sample(200,random_state=42)\n",
    "else:\n",
    "    train_data = train_data.sample(frac=1,random_state=42)\n",
    "    val_data = val_data.sample(500,random_state=42)\n",
    "    test_data = test_data.sample(frac=1,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "      <th>multiclasses</th>\n",
       "      <th>score-lv1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8600</td>\n",
       "      <td>https://files.worldwildlife.org/wwfcmsprod/fil...</td>\n",
       "      <td>PLOW 0 2 0 PRINT 2 orld Wildlife Fundâ€™s 2020 P...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8600</td>\n",
       "      <td>https://files.worldwildlife.org/wwfcmsprod/fil...</td>\n",
       "      <td>report is based on an updat- accessibility of ...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8600</td>\n",
       "      <td>https://files.worldwildlife.org/wwfcmsprod/fil...</td>\n",
       "      <td>5,000 2014 40,685,000 230,499,000 1,139,000 4,...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8599</td>\n",
       "      <td>https://www.wyomingwildsheep.org/wp-content/up...</td>\n",
       "      <td>rically, native desert bighorn sheep occupied ...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8599</td>\n",
       "      <td>https://www.wyomingwildsheep.org/wp-content/up...</td>\n",
       "      <td>ected. Ninety- During winter rams consumed mor...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>204</td>\n",
       "      <td>https://www.conservationevidence.com/individua...</td>\n",
       "      <td>bodies of 51 species were edible. The results ...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>204</td>\n",
       "      <td>https://www.conservationevidence.com/individua...</td>\n",
       "      <td>ched). Effects of trampling: Trampling signifi...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>204</td>\n",
       "      <td>https://www.conservationevidence.com/individua...</td>\n",
       "      <td>nnual differences. In every year, the number o...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>204</td>\n",
       "      <td>https://www.conservationevidence.com/individua...</td>\n",
       "      <td>trampled plots (195 and 189, respectively).Con...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>204</td>\n",
       "      <td>https://www.conservationevidence.com/individua...</td>\n",
       "      <td>an be established with certainty. Harvesting g...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chunk_id                                                url  \\\n",
       "0        8600  https://files.worldwildlife.org/wwfcmsprod/fil...   \n",
       "1        8600  https://files.worldwildlife.org/wwfcmsprod/fil...   \n",
       "2        8600  https://files.worldwildlife.org/wwfcmsprod/fil...   \n",
       "3        8599  https://www.wyomingwildsheep.org/wp-content/up...   \n",
       "4        8599  https://www.wyomingwildsheep.org/wp-content/up...   \n",
       "..        ...                                                ...   \n",
       "495       204  https://www.conservationevidence.com/individua...   \n",
       "496       204  https://www.conservationevidence.com/individua...   \n",
       "497       204  https://www.conservationevidence.com/individua...   \n",
       "498       204  https://www.conservationevidence.com/individua...   \n",
       "499       204  https://www.conservationevidence.com/individua...   \n",
       "\n",
       "                                                  text   relevance  \\\n",
       "0    PLOW 0 2 0 PRINT 2 orld Wildlife Fundâ€™s 2020 P...  irrelevant   \n",
       "1    report is based on an updat- accessibility of ...  irrelevant   \n",
       "2    5,000 2014 40,685,000 230,499,000 1,139,000 4,...  irrelevant   \n",
       "3    rically, native desert bighorn sheep occupied ...  irrelevant   \n",
       "4    ected. Ninety- During winter rams consumed mor...  irrelevant   \n",
       "..                                                 ...         ...   \n",
       "495  bodies of 51 species were edible. The results ...    relevant   \n",
       "496  ched). Effects of trampling: Trampling signifi...    relevant   \n",
       "497  nnual differences. In every year, the number o...    relevant   \n",
       "498  trampled plots (195 and 189, respectively).Con...    relevant   \n",
       "499  an be established with certainty. Harvesting g...    relevant   \n",
       "\n",
       "    multiclasses  score-lv1  \n",
       "0             []        1.0  \n",
       "1             []        1.0  \n",
       "2             []        1.0  \n",
       "3             []        1.0  \n",
       "4             []        1.0  \n",
       "..           ...        ...  \n",
       "495           []        NaN  \n",
       "496           []        NaN  \n",
       "497           []        NaN  \n",
       "498           []        NaN  \n",
       "499           []        NaN  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chunk_id', 'url', 'text', 'relevance', 'multiclasses', 'score-lv1'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data, split=\"train\")\n",
    "test_dataset = Dataset.from_pandas(test_data, split=\"test\")\n",
    "val_dataset = Dataset.from_pandas(val_data, split=\"val\")\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! had to modify FastFitTrainer to at /fastfit/train.py, line 879, to add trust_remote_code=True to the loading of 'accuracy' metrics\n",
    "#! don't know why it's not default, since accuracy is the default in fastfit\n",
    "\n",
    "\n",
    "\n",
    "#! IMPORTANT: another change in FastFitTrainer, also at line 879; comment out and replace the fixed version above\n",
    "#! since load_metric is deprecated in favour of evaluate.load()\n",
    "#! added functionality for sending in multiple metrics to evaluate at once\n",
    "#! added macro averages for non-accuracy metrics too\n",
    "#! essentially, copy the below code to replace line 879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert into line 879.\n",
    "\n",
    "```python\n",
    "        # metric = load_metric(self.data_args.metric_name, experiment_id=uuid.uuid4())\n",
    "        from evaluate import combine, load\n",
    "        if type(self.data_args.metric_name) == str: # single metric name\n",
    "            metrics = [load(self.data_args.metric_name, experiment_id=uuid.uuid4())]\n",
    "        elif type(self.data_args.metric_name) == list: # compute multiple metrics\n",
    "            metrics = [load(metric,experiment_id=uuid.uuid4()) for metric in self.data_args.metric_name]\n",
    "\n",
    "        # You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "        # predictions and label_ids field) and has to return a dictionary string to float.\n",
    "        def compute_metrics(p: EvalPrediction):\n",
    "            predictions = (\n",
    "                p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "            )\n",
    "            predictions = (\n",
    "                np.squeeze(predictions)\n",
    "                if self.is_regression\n",
    "                else np.argmax(predictions, axis=1)\n",
    "            )\n",
    "            references = p.label_ids\n",
    "\n",
    "            results = {}\n",
    "\n",
    "            for metric in metrics:\n",
    "                if metric.name != 'accuracy':\n",
    "                    results.update(metric.compute(predictions=predictions, references=references,average='macro'))\n",
    "                else:\n",
    "                    results.update(metric.compute(predictions=predictions, references=references))\n",
    "\n",
    "            return results\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 3090\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "print(torch.version.cuda)\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/30/2024 10:34:07 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/GreyLiteratureClassifier-eJH_GeT1/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1383d5f97cef4659ad5a10d5258c37dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/500 [00:00<?,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beaf12880b4a4c38a068101e29f1e456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/100 [00:00<?,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba48f1b87ea84208870aa73c1b3e2323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/200 [00:00<?,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455f3cccaec3499db19e217f70faee94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442c483bc8ab41e0993c59c09310f537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbdd700fa884772b748b69b6d86176f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from fastfit import FastFitTrainer\n",
    "\n",
    "# same args as the huggingface TrainingArguments\n",
    "if DEV:\n",
    "    output_dir = f'models/relevance/dev/{model_name}'\n",
    "else:\n",
    "    output_dir = f'models/relevance/{model_name}'\n",
    "\n",
    "trainer = FastFitTrainer(\n",
    "    model_name_or_path=model_name,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    label_column_name='relevance',\n",
    "    text_column_name=\"text\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    max_text_length=512,\n",
    "    num_repeats=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy='epoch',\n",
    "    metric_name=['precision','recall','f1','accuracy'],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='recall',\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "print(trainer.model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:1198] 2024-07-30 10:34:26,453 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 00:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.989800</td>\n",
       "      <td>4.762214</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.726461</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.554000</td>\n",
       "      <td>4.818264</td>\n",
       "      <td>0.782853</td>\n",
       "      <td>0.786526</td>\n",
       "      <td>0.779647</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.475800</td>\n",
       "      <td>5.239364</td>\n",
       "      <td>0.714383</td>\n",
       "      <td>0.692370</td>\n",
       "      <td>0.693802</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.444200</td>\n",
       "      <td>5.705395</td>\n",
       "      <td>0.739389</td>\n",
       "      <td>0.728896</td>\n",
       "      <td>0.731294</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>6.216745</td>\n",
       "      <td>0.729944</td>\n",
       "      <td>0.717532</td>\n",
       "      <td>0.719888</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.431000</td>\n",
       "      <td>6.458174</td>\n",
       "      <td>0.727827</td>\n",
       "      <td>0.719968</td>\n",
       "      <td>0.721965</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.438800</td>\n",
       "      <td>6.645418</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.711039</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.421600</td>\n",
       "      <td>6.773955</td>\n",
       "      <td>0.727827</td>\n",
       "      <td>0.719968</td>\n",
       "      <td>0.721965</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.431600</td>\n",
       "      <td>6.847547</td>\n",
       "      <td>0.727827</td>\n",
       "      <td>0.719968</td>\n",
       "      <td>0.721965</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.435200</td>\n",
       "      <td>6.868251</td>\n",
       "      <td>0.727827</td>\n",
       "      <td>0.719968</td>\n",
       "      <td>0.721965</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     3.5059\n",
      "  train_runtime            = 0:00:54.96\n",
      "  train_samples            =        500\n",
      "  train_samples_per_second =     90.968\n",
      "  train_steps_per_second   =      2.911\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#! another fastfit library modification\n",
    "#! in /fastfit/train.py, line 971, change ignore_keys_for_eval from type set to a list\n",
    "#! since it gets concatenated to a list later on\n",
    "#! note that since we've added lines above, this is now line 981\n",
    "#! the line beginning ignore_keys_for_eval={\"doc_input_ids\",\"doc_attention_mask\",\"labels\"}\n",
    "\n",
    "\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =       0.78\n",
      "  eval_f1                 =     0.7796\n",
      "  eval_loss               =     4.8183\n",
      "  eval_precision          =     0.7829\n",
      "  eval_recall             =     0.7865\n",
      "  eval_runtime            = 0:00:00.39\n",
      "  eval_samples            =        100\n",
      "  eval_samples_per_second =    251.615\n",
      "  eval_steps_per_second   =      5.032\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.818263530731201,\n",
       " 'eval_precision': 0.7828525641025641,\n",
       " 'eval_recall': 0.786525974025974,\n",
       " 'eval_f1': 0.7796474358974359,\n",
       " 'eval_accuracy': 0.78,\n",
       " 'eval_runtime': 0.3974,\n",
       " 'eval_samples_per_second': 251.615,\n",
       " 'eval_steps_per_second': 5.032,\n",
       " 'epoch': 10.0,\n",
       " 'eval_samples': 100}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {results[\"eval_accuracy\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =      0.795\n",
      "  eval_f1                 =     0.7944\n",
      "  eval_loss               =     4.8178\n",
      "  eval_precision          =     0.8114\n",
      "  eval_recall             =     0.8028\n",
      "  eval_runtime            = 0:00:00.69\n",
      "  eval_samples_per_second =    287.624\n",
      "  eval_steps_per_second   =      5.752\n",
      "  test_samples            =        200\n"
     ]
    }
   ],
   "source": [
    "results = trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from os import makedirs, path\n",
    "if not path.exists(f'models/relevance/dev/{model_name}'):\n",
    "    makedirs(f'models/relevance/dev/{model_name}')\n",
    "\n",
    "model.save_pretrained(f'models/relevance/dev/{model_name}')\n",
    "\n",
    "if not DEV:\n",
    "    model.save_pretrained(f'models/relevance/{model_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreyLiteratureClassifier-pwi3iMQR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
