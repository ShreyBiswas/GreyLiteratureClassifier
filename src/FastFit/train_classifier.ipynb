{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_type = 'relevance'\n",
    "model_name = \"avsolatorio/GIST-small-Embedding-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20901 entries, 0 to 20900\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   url           20901 non-null  object\n",
      " 1   text          20901 non-null  object\n",
      " 2   relevance     20901 non-null  object\n",
      " 3   multiclasses  20901 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 653.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "      <th>multiclasses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>1 \\n \\n \\n2 \\n \\n \\nSubtidal Benthic Invertebr...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Marine Invertebrates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>\\n \\n   \\n  Control of freshwater  \\n  invasi...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Fish, Rivers and Lakes, Invasive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>1 \\n \\nGrassland Conservation \\n2 \\n \\nGrassla...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Grassland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>\\n \\n \\nii \\n \\n \\n \\n \\n \\n \\n  \\nPrimate Co...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Mammals]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.conservationevidence.com/synopsis/...</td>\n",
       "      <td>CONSERVATION EVIDENCE SERIES SYNOPSES\\nTerrest...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[Mammals]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.conservationevidence.com/synopsis/...   \n",
       "1  https://www.conservationevidence.com/synopsis/...   \n",
       "2  https://www.conservationevidence.com/synopsis/...   \n",
       "3  https://www.conservationevidence.com/synopsis/...   \n",
       "4  https://www.conservationevidence.com/synopsis/...   \n",
       "\n",
       "                                                text relevance  \\\n",
       "0  1 \\n \\n \\n2 \\n \\n \\nSubtidal Benthic Invertebr...  relevant   \n",
       "1   \\n \\n   \\n  Control of freshwater  \\n  invasi...  relevant   \n",
       "2  1 \\n \\nGrassland Conservation \\n2 \\n \\nGrassla...  relevant   \n",
       "3   \\n \\n \\nii \\n \\n \\n \\n \\n \\n \\n  \\nPrimate Co...  relevant   \n",
       "4  CONSERVATION EVIDENCE SERIES SYNOPSES\\nTerrest...  relevant   \n",
       "\n",
       "                         multiclasses  \n",
       "0              [Marine Invertebrates]  \n",
       "1  [Fish, Rivers and Lakes, Invasive]  \n",
       "2                         [Grassland]  \n",
       "3                           [Mammals]  \n",
       "4                           [Mammals]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_labelled_data(path=\"data/labelled/data.json\"):\n",
    "    data = pd.read_json(path, encoding=\"latin-1\")\n",
    "    return data\n",
    "\n",
    "\n",
    "data = import_labelled_data(path=\"../../data/labelled/data.json\", )\n",
    "\n",
    "\n",
    "\n",
    "if classifier_type == 'multiclasses':\n",
    "    # drop irrelevant parts\n",
    "    data = data[data[\"relevance\"] != \"irrelevant\"]\n",
    "\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0.49, 0.21, 0.3 split\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.3, random_state=42)\n",
    "\n",
    "display(data.info())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunking import chunk_dataset_and_explode\n",
    "\n",
    "\n",
    "# roughly 4 characters per token\n",
    "max_len = 512\n",
    "\n",
    "train_data = chunk_dataset_and_explode(train_data, max_len=max_len, overlap=int(max_len * 0.2))\n",
    "test_data = chunk_dataset_and_explode(test_data, max_len=max_len, overlap=int(max_len * 0.2))\n",
    "val_data = chunk_dataset_and_explode(val_data, max_len=max_len, overlap=int(max_len * 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chunk_id', 'url', 'text', 'relevance', 'multiclasses'],\n",
       "    num_rows: 1660297\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data, split=\"train\")\n",
    "test_dataset = Dataset.from_pandas(test_data, split=\"test\")\n",
    "val_dataset = Dataset.from_pandas(val_data, split=\"val\")\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastfit import sample_dataset, FastFitTrainer\n",
    "\n",
    "if classifier_type == 'relevance':\n",
    "    num_samples_per_label = 500\n",
    "elif classifier_type == 'multiclasses':\n",
    "    num_samples_per_label = 50\n",
    "\n",
    "train_dataset = sample_dataset(train_dataset, label_column=classifier_type,num_samples_per_label=num_samples_per_label,seed=42)\n",
    "val_dataset = val_dataset.select(range(500)).shuffle(seed=42)\n",
    "test_dataset = test_dataset.select(range(500)).shuffle(seed=42)\n",
    "\n",
    "# train_dataset, val_dataset, test_dataset = train_dataset.shuffle(seed=42), val_dataset.shuffle(seed=42), test_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! had to modify FastFitTrainer to at /fastfit/train.py, line 879, to add trust_remote_code=True to the loading of 'accuracy' metrics\n",
    "#! don't know why it's not default, since accuracy is the default in fastfit\n",
    "\n",
    "\n",
    "\n",
    "#! IMPORTANT: another change in FastFitTrainer, also at line 879; comment out and replace the fixed version above\n",
    "#! since load_metric is deprecated in favour of evaluate.load()\n",
    "#! added functionality for sending in multiple metrics to evaluate at once\n",
    "#! added macro averages for non-accuracy metrics too\n",
    "#! essentially, copy the below code to replace line 879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert into line 879.\n",
    "\n",
    "```python\n",
    "        # metric = load_metric(self.data_args.metric_name, experiment_id=uuid.uuid4())\n",
    "        from evaluate import combine, load\n",
    "        if type(self.data_args.metric_name) == str: # single metric name\n",
    "            metrics = [load(self.data_args.metric_name, experiment_id=uuid.uuid4())]\n",
    "        elif type(self.data_args.metric_name) == list: # compute multiple metrics\n",
    "            metrics = [load(metric,experiment_id=uuid.uuid4()) for metric in self.data_args.metric_name]\n",
    "\n",
    "        # You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "        # predictions and label_ids field) and has to return a dictionary string to float.\n",
    "        def compute_metrics(p: EvalPrediction):\n",
    "            predictions = (\n",
    "                p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "            )\n",
    "            predictions = (\n",
    "                np.squeeze(predictions)\n",
    "                if self.is_regression\n",
    "                else np.argmax(predictions, axis=1)\n",
    "            )\n",
    "            references = p.label_ids\n",
    "\n",
    "            results = {}\n",
    "\n",
    "            for metric in metrics:\n",
    "                if metric.name != 'accuracy':\n",
    "                    results.update(metric.compute(predictions=predictions, references=references,average='macro'))\n",
    "                else:\n",
    "                    results.update(metric.compute(predictions=predictions, references=references))\n",
    "\n",
    "            return results\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/GreyLiteratureClassifier-eJH_GeT1/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/25/2024 15:13:09 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4923f7553b49d38eeb478c715e369d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/500 [00:00<?,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3671c8abd074e5392f97c95718b3cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/500 [00:00<?,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c2a5978dee43c8a58b7bf13859fba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/500 [00:00<?,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e9e0f025274a3293c2f4e3982847de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f227618f54c4526921b36cf5b300761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ac2a18184348bf9b8b51fbea89ca6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same args as the huggingface TrainingArguments\n",
    "\n",
    "\n",
    "trainer = FastFitTrainer(\n",
    "    model_name_or_path=model_name,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    output_dir=f'models/{classifier_type}/{model_name}',\n",
    "    overwrite_output_dir=True,\n",
    "    label_column_name=classifier_type,\n",
    "    text_column_name=\"text\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    max_text_length=512,\n",
    "    num_repeats=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    logging_strategy='epoch',\n",
    "    metric_name=['precision','recall','f1','accuracy'],\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 3090\n",
      "12.1\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "print(torch.version.cuda)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(trainer.model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:1198] 2024-07-25 15:14:17,324 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.897700</td>\n",
       "      <td>4.587396</td>\n",
       "      <td>0.980287</td>\n",
       "      <td>0.976293</td>\n",
       "      <td>0.977804</td>\n",
       "      <td>0.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.406800</td>\n",
       "      <td>4.358639</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.967650</td>\n",
       "      <td>0.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.309200</td>\n",
       "      <td>4.313827</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.967650</td>\n",
       "      <td>0.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.250800</td>\n",
       "      <td>4.314916</td>\n",
       "      <td>0.968531</td>\n",
       "      <td>0.961207</td>\n",
       "      <td>0.963575</td>\n",
       "      <td>0.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.235200</td>\n",
       "      <td>4.300236</td>\n",
       "      <td>0.976868</td>\n",
       "      <td>0.971983</td>\n",
       "      <td>0.973748</td>\n",
       "      <td>0.974000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        5.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     4.4199\n",
      "  train_runtime            = 0:00:32.40\n",
      "  train_samples            =        500\n",
      "  train_samples_per_second =      77.15\n",
      "  train_steps_per_second   =      1.234\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#! another fastfit library modification\n",
    "#! in /fastfit/train.py, line 971, change ignore_keys_for_eval from type set to a list\n",
    "#! since it gets concatenated to a list later on\n",
    "#! note that since we've added lines above, this is now line 981\n",
    "#! the line beginning ignore_keys_for_eval={\"doc_input_ids\",\"doc_attention_mask\",\"labels\"}\n",
    "\n",
    "\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        5.0\n",
      "  eval_accuracy           =      0.974\n",
      "  eval_f1                 =     0.9737\n",
      "  eval_loss               =     4.3002\n",
      "  eval_precision          =     0.9769\n",
      "  eval_recall             =      0.972\n",
      "  eval_runtime            = 0:00:01.98\n",
      "  eval_samples            =        500\n",
      "  eval_samples_per_second =    251.886\n",
      "  eval_steps_per_second   =       4.03\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {results[\"eval_accuracy\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f'models/{classifier_type}/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test metrics *****\n",
      "  epoch                   =        5.0\n",
      "  eval_accuracy           =        1.0\n",
      "  eval_f1                 =        1.0\n",
      "  eval_loss               =     4.7645\n",
      "  eval_precision          =        1.0\n",
      "  eval_recall             =        1.0\n",
      "  eval_runtime            = 0:00:01.99\n",
      "  eval_samples_per_second =    250.794\n",
      "  eval_steps_per_second   =      4.013\n",
      "  test_samples            =        500\n"
     ]
    }
   ],
   "source": [
    "results = trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastFit(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (projection): Linear(in_features=384, out_features=128, bias=False)\n",
       "  (clf): Linear(in_features=384, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (clf_criterion): CrossEntropyLoss()\n",
       "  (sim_criterion): SupConLoss()\n",
       "  (all_docs): ParameterList(\n",
       "      (0): Parameter containing: [torch.int64 of size 2x3 (cuda:0)]\n",
       "      (1): Parameter containing: [torch.int64 of size 2x3 (cuda:0)]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on the test set\n",
    "model = trainer.export_model()\n",
    "model.cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreyLiteratureClassifier-pwi3iMQR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
