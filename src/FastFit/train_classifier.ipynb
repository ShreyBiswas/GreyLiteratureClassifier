{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV = False\n",
    "model_name = \"avsolatorio/GIST-small-Embedding-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.wetlands.org/wp-content/uploads/20...</td>\n",
       "      <td>\\n \\n \\nFlamingo\\nFlamingo\\nFlamingo\\nFlaming...</td>\n",
       "      <td>Birds</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.wetlands.org/publications/flamingo...</td>\n",
       "      <td>\\n\\n \\n \\n \\n \\n \\n \\nABOUT THE GROUP \\n \\nThe...</td>\n",
       "      <td>Birds</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.wetlands.org/publications/the-stat...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n(FIRST PAGE) \\n \\n \\n \\n \\nTHE STA...</td>\n",
       "      <td>Birds</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>\\nPlease contact us via our\\nsupport center fo...</td>\n",
       "      <td>Mammals</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.wetlands.org/publications/strategi...</td>\n",
       "      <td>Strategies for wise use of Wetlands:\\nBest Pra...</td>\n",
       "      <td>Wetlands</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.wetlands.org/wp-content/uploads/20...   \n",
       "1  https://www.wetlands.org/publications/flamingo...   \n",
       "2  https://www.wetlands.org/publications/the-stat...   \n",
       "3  https://www.sciencedirect.com/science/article/...   \n",
       "4  https://www.wetlands.org/publications/strategi...   \n",
       "\n",
       "                                                text     class relevance  \n",
       "0   \\n \\n \\nFlamingo\\nFlamingo\\nFlamingo\\nFlaming...     Birds  relevant  \n",
       "1  \\n\\n \\n \\n \\n \\n \\n \\nABOUT THE GROUP \\n \\nThe...     Birds  relevant  \n",
       "2  \\n\\n\\n\\n\\n\\n(FIRST PAGE) \\n \\n \\n \\n \\nTHE STA...     Birds  relevant  \n",
       "3  \\nPlease contact us via our\\nsupport center fo...   Mammals  relevant  \n",
       "4  Strategies for wise use of Wetlands:\\nBest Pra...  Wetlands  relevant  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_labelled_data(path=\"data/labelled/data.json\", group_relevant=True):\n",
    "    data = pd.read_json(path, encoding=\"latin-1\")\n",
    "    data[\"relevance\"] = data[\"class\"].apply(\n",
    "        lambda x: \"relevant\" if x != \"irrelevant\" else x\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "data = import_labelled_data(path=\"../../data/labelled/data.json\", group_relevant=False)\n",
    "\n",
    "# drop null classes\n",
    "data = data.dropna(subset=[\"class\"])\n",
    "\n",
    "\n",
    "if DEV:\n",
    "    data = data.sample(5000)\n",
    "\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunking import chunk_dataset_and_explode\n",
    "\n",
    "\n",
    "# roughly 4 characters per token\n",
    "max_len = 2048\n",
    "\n",
    "train_data = chunk_dataset_and_explode(train_data, max_len=max_len, overlap=int(max_len * 0.2))\n",
    "test_data = chunk_dataset_and_explode(test_data, max_len=max_len, overlap=int(max_len * 0.2))\n",
    "val_data = chunk_dataset_and_explode(val_data, max_len=max_len, overlap=int(max_len * 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chunk_id', 'url', 'text', 'class', 'relevance'],\n",
       "    num_rows: 93801\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data, split=\"train\")\n",
    "test_dataset = Dataset.from_pandas(test_data, split=\"test\")\n",
    "val_dataset = Dataset.from_pandas(val_data, split=\"val\")\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastfit import sample_dataset, FastFitTrainer\n",
    "\n",
    "\n",
    "train_dataset = sample_dataset(train_dataset, label_column='relevance',num_samples_per_label=150,seed=42)\n",
    "val_dataset = val_dataset.shuffle(seed=42).select(range(200))\n",
    "test_dataset = test_dataset.shuffle(seed=42).select(range(1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! had to modify FastFitTrainer to at /fastfit/train.py, line 879, to add trust_remote_code=True to the loading of 'accuracy' metrics\n",
    "#! don't know why it's not default, since accuracy is the default in fastfit\n",
    "\n",
    "#* note that since SetFit uses evaluation_strategy as the argument name rather than eval_strategy\n",
    "#* I had to change it in the FastFitTrainer call below\n",
    "#* if using the latest transformers version (transformers>=4.41.0), use eval_strategy\n",
    "\n",
    "#! another change in FastFitTrainer, also at line 879; commented out the fixed version above\n",
    "#! since load_metric is deprecated in favour of evaluate.load()\n",
    "#! using evaluate means we can use evaluate.combine(), which lets us calculate multiple metrics at once\n",
    "#! also, add the ability to just send in our own compute_metrics function\n",
    "#! essentially, copy the below code to replace line 879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert into line 879.\n",
    "\n",
    "```python\n",
    "        # metric = load_metric(self.data_args.metric_name, experiment_id=uuid.uuid4())\n",
    "        from evaluate import combine, load\n",
    "        if type(self.data_args.metric_name) == str: # single metric name\n",
    "            metrics = [load(self.data_args.metric_name, experiment_id=uuid.uuid4())]\n",
    "        elif type(self.data_args.metric_name) == list: # compute multiple metrics\n",
    "            metrics = [load(metric,experiment_id=uuid.uuid4()) for metric in self.data_args.metric_name]\n",
    "\n",
    "        # You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "        # predictions and label_ids field) and has to return a dictionary string to float.\n",
    "        def compute_metrics(p: EvalPrediction):\n",
    "            predictions = (\n",
    "                p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "            )\n",
    "            predictions = (\n",
    "                np.squeeze(predictions)\n",
    "                if self.is_regression\n",
    "                else np.argmax(predictions, axis=1)\n",
    "            )\n",
    "            references = p.label_ids\n",
    "\n",
    "            results = {}\n",
    "\n",
    "            for metric in metrics:\n",
    "                if metric.name != 'accuracy':\n",
    "                    results.update(metric.compute(predictions=predictions, references=references,average='macro'))\n",
    "                else:\n",
    "                    results.update(metric.compute(predictions=predictions, references=references))\n",
    "\n",
    "            return results\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/23/2024 13:11:26 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/GreyLiteratureClassifier-eJH_GeT1/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f192fb44e2eb406386a7554e9c8011ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f0023101b642ce9f720c6c5abd9682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b3821e624b416d91a5c6dcf319408a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/300 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c635c4da5a2e4143bc01852101b8e414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/200 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d36e95f05848538ed07437b7d2a767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/1500 [00:00<?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264a2688c8ad47abbb069db916d0ad16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b524c5426d449819a39b747ffc6e7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b3140d548e4c07bf3f872268900ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same args as the huggingface TrainingArguments\n",
    "\n",
    "\n",
    "trainer = FastFitTrainer(\n",
    "    model_name_or_path=model_name,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    output_dir=f'models/{model_name}',\n",
    "    overwrite_output_dir=True,\n",
    "    label_column_name=\"relevance\",\n",
    "    text_column_name=\"text\",\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    max_text_length=2048,\n",
    "    seed=42,\n",
    "    num_repeats=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    logging_steps=1,\n",
    "    metric_name=['precision','accuracy','f1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:1198] 2024-07-23 13:11:55,196 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 01:02, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.299000</td>\n",
       "      <td>4.486239</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.974536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.960200</td>\n",
       "      <td>4.249883</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.989770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.889800</td>\n",
       "      <td>4.215590</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.989770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.838900</td>\n",
       "      <td>4.182333</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.820600</td>\n",
       "      <td>4.225021</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.814100</td>\n",
       "      <td>4.203435</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.808900</td>\n",
       "      <td>4.185344</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.799500</td>\n",
       "      <td>4.189375</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.797700</td>\n",
       "      <td>4.207275</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.790500</td>\n",
       "      <td>4.220812</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.787500</td>\n",
       "      <td>4.224126</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.809900</td>\n",
       "      <td>4.224823</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.781900</td>\n",
       "      <td>4.224779</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.784200</td>\n",
       "      <td>4.225880</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.780000</td>\n",
       "      <td>4.226571</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.787400</td>\n",
       "      <td>4.227510</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.778700</td>\n",
       "      <td>4.228671</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.777100</td>\n",
       "      <td>4.229467</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.776700</td>\n",
       "      <td>4.229557</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.776200</td>\n",
       "      <td>4.229523</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.984678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       20.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     4.1634\n",
      "  train_runtime            = 0:01:03.99\n",
      "  train_samples            =        300\n",
      "  train_samples_per_second =     93.752\n",
      "  train_steps_per_second   =      1.563\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#! another fastfit library modification\n",
    "#! in /fastfit/train.py, line 971, change ignore_keys_for_eval from type set to a list\n",
    "#! since it gets concatenated to a list later on\n",
    "#! note that since we've added lines above, this is now line 981\n",
    "#! the line beginning ignore_keys_for_eval={\"doc_input_ids\",\"doc_attention_mask\",\"labels\"}\n",
    "\n",
    "\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       20.0\n",
      "  eval_accuracy           =      0.985\n",
      "  eval_f1                 =     0.9847\n",
      "  eval_loss               =     4.2295\n",
      "  eval_precision          =     0.9828\n",
      "  eval_runtime            = 0:00:01.04\n",
      "  eval_samples            =        200\n",
      "  eval_samples_per_second =    192.102\n",
      "  eval_steps_per_second   =      3.842\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.985\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {results[\"eval_accuracy\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f'models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test metrics *****\n",
      "  epoch                   =       20.0\n",
      "  eval_accuracy           =     0.9833\n",
      "  eval_f1                 =     0.9819\n",
      "  eval_loss               =     4.3387\n",
      "  eval_precision          =     0.9802\n",
      "  eval_runtime            = 0:00:06.81\n",
      "  eval_samples_per_second =    220.039\n",
      "  eval_steps_per_second   =      3.521\n",
      "  test_samples            =       1500\n"
     ]
    }
   ],
   "source": [
    "results = trainer.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreyLiteratureClassifier-pwi3iMQR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
